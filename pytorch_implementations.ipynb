{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565b0985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp39-cp39-win_amd64.whl (167.2 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cc27ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 4019.6084\n",
      "epoch: 20, loss = 2832.6216\n",
      "epoch: 30, loss = 2023.7903\n",
      "epoch: 40, loss = 1472.5177\n",
      "epoch: 50, loss = 1096.7070\n",
      "epoch: 60, loss = 840.4568\n",
      "epoch: 70, loss = 665.6937\n",
      "epoch: 80, loss = 546.4807\n",
      "epoch: 90, loss = 465.1443\n",
      "epoch: 100, loss = 409.6393\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#linear regression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "n_samples, n_features = X.shape\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c914e1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 0.6987\n",
      "epoch: 20, loss = 0.5412\n",
      "epoch: 30, loss = 0.4504\n",
      "epoch: 40, loss = 0.3920\n",
      "epoch: 50, loss = 0.3511\n",
      "epoch: 60, loss = 0.3207\n",
      "epoch: 70, loss = 0.2970\n",
      "epoch: 80, loss = 0.2779\n",
      "epoch: 90, loss = 0.2621\n",
      "epoch: 100, loss = 0.2488\n",
      "accuracy: 0.9035\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "n_samples, n_features = X.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "model = Model(n_features)\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy: {acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8cd710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchvision) (4.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: torch==1.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f361508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/5], Step [2000/12500], Loss: 2.2843\n",
      "Epoch [1/5], Step [4000/12500], Loss: 2.3034\n",
      "Epoch [1/5], Step [6000/12500], Loss: 2.3024\n",
      "Epoch [1/5], Step [8000/12500], Loss: 2.2720\n",
      "Epoch [1/5], Step [10000/12500], Loss: 2.2995\n",
      "Epoch [1/5], Step [12000/12500], Loss: 2.4794\n",
      "Epoch [2/5], Step [2000/12500], Loss: 2.1262\n",
      "Epoch [2/5], Step [4000/12500], Loss: 2.1797\n",
      "Epoch [2/5], Step [6000/12500], Loss: 2.5740\n",
      "Epoch [2/5], Step [8000/12500], Loss: 1.4910\n",
      "Epoch [2/5], Step [10000/12500], Loss: 1.7833\n",
      "Epoch [2/5], Step [12000/12500], Loss: 1.3443\n",
      "Epoch [3/5], Step [2000/12500], Loss: 1.2591\n",
      "Epoch [3/5], Step [4000/12500], Loss: 2.1910\n",
      "Epoch [3/5], Step [6000/12500], Loss: 1.4156\n",
      "Epoch [3/5], Step [8000/12500], Loss: 2.0752\n",
      "Epoch [3/5], Step [10000/12500], Loss: 2.1616\n",
      "Epoch [3/5], Step [12000/12500], Loss: 2.1834\n",
      "Epoch [4/5], Step [2000/12500], Loss: 1.1841\n",
      "Epoch [4/5], Step [4000/12500], Loss: 1.2549\n",
      "Epoch [4/5], Step [6000/12500], Loss: 1.0644\n",
      "Epoch [4/5], Step [8000/12500], Loss: 2.1482\n",
      "Epoch [4/5], Step [10000/12500], Loss: 0.9056\n",
      "Epoch [4/5], Step [12000/12500], Loss: 1.0000\n",
      "Epoch [5/5], Step [2000/12500], Loss: 2.0132\n",
      "Epoch [5/5], Step [4000/12500], Loss: 1.1708\n",
      "Epoch [5/5], Step [6000/12500], Loss: 1.5201\n",
      "Epoch [5/5], Step [8000/12500], Loss: 1.3204\n",
      "Epoch [5/5], Step [10000/12500], Loss: 1.7046\n",
      "Epoch [5/5], Step [12000/12500], Loss: 1.7261\n",
      "Finished Training\n",
      "Accuracy of the network: 49.1 %\n",
      "Accuracy of plane: 52.9 %\n",
      "Accuracy of car: 61.9 %\n",
      "Accuracy of bird: 34.7 %\n",
      "Accuracy of cat: 31.5 %\n",
      "Accuracy of deer: 22.2 %\n",
      "Accuracy of dog: 60.1 %\n",
      "Accuracy of frog: 52.3 %\n",
      "Accuracy of horse: 55.6 %\n",
      "Accuracy of ship: 61.3 %\n",
      "Accuracy of truck: 58.5 %\n"
     ]
    }
   ],
   "source": [
    "#cnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5,120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)    \n",
    "        x = F.relu(self.fc1(x))       \n",
    "        x = F.relu(self.fc2(x))     \n",
    "        x = self.fc3(x)            \n",
    "        return x\n",
    "model = ConvNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        value, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
