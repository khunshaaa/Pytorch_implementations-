{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Convolutional Neural Network (CNN or ConvNet)**"
      ],
      "metadata": {
        "id": "Y1wLtKkj43nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Networks (CNNs) are the backbone of image classification, a deep learning phenomenon that takes an image and assigns it a class and a label that makes it unique. Image classification using CNN forms a significant part of machine learning experiments."
      ],
      "metadata": {
        "id": "Z6qrBcx15Biy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation of Convolutional Neural Network from scratch** "
      ],
      "metadata": {
        "id": "4VA0leFV5lQL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLiYIs0lqjh5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class ConvolutionLayer:\n",
        "    def __init__(self, kernel_num, kernel_size):\n",
        "        self.kernel_num = kernel_num\n",
        "        self.kernel_size = kernel_size      \n",
        "          \n",
        "        self.kernels = np.random.randn(kernel_num, kernel_size, kernel_size) / (kernel_size**2)\n",
        "\n",
        "    def patches_generator(self, image):\n",
        "        image_h, image_w = image.shape\n",
        "        self.image = image\n",
        "\n",
        "        for h in range(image_h-self.kernel_size+1):\n",
        "            for w in range(image_w-self.kernel_size+1):\n",
        "                patch = image[h:(h+self.kernel_size), w:(w+self.kernel_size)]\n",
        "\n",
        "                yield patch, h, w\n",
        "    \n",
        "    def forward_prop(self, image):\n",
        "        image_h, image_w = image.shape\n",
        "        convolution_output = np.zeros((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_num))\n",
        "\n",
        "        for patch, h, w in self.patches_generator(image):\n",
        "            convolution_output[h,w] = np.sum(patch*self.kernels, axis=(1,2))\n",
        "\n",
        "        return convolution_output\n",
        "    \n",
        "    def back_prop(self, dE_dY, alpha):\n",
        "        dE_dk = np.zeros(self.kernels.shape)\n",
        "\n",
        "        for patch, h, w in self.patches_generator(self.image):\n",
        "            for f in range(self.kernel_num):\n",
        "                dE_dk[f] += patch * dE_dY[h, w, f]\n",
        "\n",
        "        self.kernels -= alpha*dE_dk\n",
        "\n",
        "        return dE_dk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPoolingLayer:\n",
        "    def __init__(self, kernel_size):\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def patches_generator(self, image):\n",
        "        output_h = image.shape[0] // self.kernel_size\n",
        "        output_w = image.shape[1] // self.kernel_size\n",
        "\n",
        "        self.image = image\n",
        "\n",
        "        for h in range(output_h):\n",
        "            for w in range(output_w):\n",
        "                patch = image[(h*self.kernel_size):(h*self.kernel_size+self.kernel_size), (w*self.kernel_size):(w*self.kernel_size+self.kernel_size)]\n",
        "                \n",
        "                yield patch, h, w\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "        image_h, image_w, num_kernels = image.shape\n",
        "        max_pooling_output = np.zeros((image_h//self.kernel_size, image_w//self.kernel_size, num_kernels))\n",
        "\n",
        "        for patch, h, w in self.patches_generator(image):\n",
        "            max_pooling_output[h,w] = np.amax(patch, axis=(0,1))\n",
        "        \n",
        "        return max_pooling_output\n",
        "\n",
        "    def back_prop(self, dE_dY):\n",
        "        dE_dk = np.zeros(self.image.shape)\n",
        "\n",
        "        for patch,h,w in self.patches_generator(self.image):\n",
        "            image_h, image_w, num_kernels = patch.shape\n",
        "            \n",
        "            max_val = np.amax(patch, axis=(0,1))\n",
        "\n",
        "            for idx_h in range(image_h):\n",
        "                for idx_w in range(image_w):\n",
        "                    for idx_k in range(num_kernels):\n",
        "                        if patch[idx_h,idx_w,idx_k] == max_val[idx_k]:\n",
        "                            dE_dk[h*self.kernel_size+idx_h, w*self.kernel_size+idx_w, idx_k] = dE_dY[h,w,idx_k]\n",
        "\n",
        "            return dE_dk"
      ],
      "metadata": {
        "id": "8urBApmRqpFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxLayer:\n",
        "    def __init__(self, input_units, output_units):\n",
        "        self.weight = np.random.randn(input_units, output_units)/input_units\n",
        "        self.bias = np.zeros(output_units)\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "        self.original_shape = image.shape\n",
        "\n",
        "        image_flattened = image.flatten()\n",
        "        self.flattened_input = image_flattened\n",
        "\n",
        "        first_output = np.dot(image_flattened, self.weight) + self.bias\n",
        "        self.output = first_output\n",
        "\n",
        "        softmax_output = np.exp(first_output) / np.sum(np.exp(first_output), axis=0)\n",
        "\n",
        "        return softmax_output\n",
        "\n",
        "    def back_prop(self, dE_dY, alpha):\n",
        "        for i, gradient in enumerate(dE_dY):\n",
        "            if gradient == 0:\n",
        "                continue\n",
        "\n",
        "            transformation_eq = np.exp(self.output)\n",
        "            S_total = np.sum(transformation_eq)\n",
        "\n",
        "            dY_dZ = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
        "            dY_dZ[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
        "            dZ_dw = self.flattened_input\n",
        "            dZ_db = 1\n",
        "            dZ_dX = self.weight\n",
        "            dE_dZ = gradient * dY_dZ\n",
        "            dE_dw = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]\n",
        "            dE_db = dE_dZ * dZ_db\n",
        "            dE_dX = dZ_dX @ dE_dZ\n",
        "            \n",
        "            self.weight -= alpha*dE_dw\n",
        "            self.bias -= alpha*dE_db\n",
        "\n",
        "            return dE_dX.reshape(self.original_shape)"
      ],
      "metadata": {
        "id": "Op4CylquqpJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def CNN_forward(image, label, layers):\n",
        "    output = image/255.\n",
        "\n",
        "    for layer in layers:\n",
        "        output = layer.forward_prop(output)\n",
        "\n",
        "    loss = -np.log(output[label])\n",
        "\n",
        "    accuracy = 1 if np.argmax(output) == label else 0\n",
        "\n",
        "    return output, loss, accuracy\n",
        "\n",
        "def CNN_backprop(gradient, layers, alpha=0.05):\n",
        "    grad_back = gradient\n",
        "\n",
        "    for layer in layers[::-1]:\n",
        "        if type(layer) in [ConvolutionLayer, SoftmaxLayer]:\n",
        "            grad_back = layer.back_prop(grad_back, alpha)\n",
        "        elif type(layer) == MaxPoolingLayer:\n",
        "            grad_back = layer.back_prop(grad_back)\n",
        "\n",
        "    return grad_back\n",
        "\n",
        "def CNN_training(image, label, layers, alpha=0.05):\n",
        "    output, loss, accuracy = CNN_forward(image, label, layers)\n",
        "\n",
        "    gradient = np.zeros(10)\n",
        "    gradient[label] = -1/output[label]\n",
        "    gradient_back = CNN_backprop(gradient, layers, alpha)\n",
        "\n",
        "    return loss, accuracy\n",
        "\n",
        "def start():\n",
        "  (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "  X_train = X_train[:1000]\n",
        "  y_train = y_train[:1000]\n",
        "\n",
        "  layers = [\n",
        "    ConvolutionLayer(16,3),\n",
        "    MaxPoolingLayer(2),\n",
        "    SoftmaxLayer(13*13*16, 10)\n",
        "    ] \n",
        "\n",
        "  for epoch in range(2):\n",
        "    print(f'Epoch {epoch+1}')\n",
        "\n",
        "    permutation = np.random.permutation(len(X_train))\n",
        "\n",
        "    X_train = X_train[permutation]\n",
        "    y_train = y_train[permutation]\n",
        "\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    for i, (image, label) in enumerate(zip(X_train, y_train)):\n",
        "      if i % 100 == 0:\n",
        "        print(\"Step {}. For the last 100 steps: average loss {}, accuracy {}\".format(i+1, loss/100, accuracy))\n",
        "        loss = 0\n",
        "        accuracy = 0\n",
        "        \n",
        "      loss_1, accuracy_1 = CNN_training(image, label, layers)\n",
        "      loss += loss_1\n",
        "      accuracy += accuracy_1\n",
        "    \n",
        "start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh5VxJiYqpNI",
        "outputId": "91fd1c3e-cdcc-4d28-ac48-b8c1343403f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1\n",
            "Step 1. For the last 100 steps: average loss 0.0, accuracy 0\n",
            "Step 101. For the last 100 steps: average loss 1.8877764570555373, accuracy 39\n",
            "Step 201. For the last 100 steps: average loss 1.183845210323902, accuracy 67\n",
            "Step 301. For the last 100 steps: average loss 0.8188547715988486, accuracy 80\n",
            "Step 401. For the last 100 steps: average loss 0.8735862611306051, accuracy 76\n",
            "Step 501. For the last 100 steps: average loss 0.6414974321712166, accuracy 81\n",
            "Step 601. For the last 100 steps: average loss 0.7108755340697958, accuracy 79\n",
            "Step 701. For the last 100 steps: average loss 0.5790089486478607, accuracy 84\n",
            "Step 801. For the last 100 steps: average loss 0.5803277389590249, accuracy 84\n",
            "Step 901. For the last 100 steps: average loss 0.4852792079010078, accuracy 87\n",
            "Epoch 2\n",
            "Step 1. For the last 100 steps: average loss 0.0, accuracy 0\n",
            "Step 101. For the last 100 steps: average loss 0.384979168520188, accuracy 88\n",
            "Step 201. For the last 100 steps: average loss 0.3663918866931457, accuracy 88\n",
            "Step 301. For the last 100 steps: average loss 0.30326250308894137, accuracy 94\n",
            "Step 401. For the last 100 steps: average loss 0.43921750977333185, accuracy 88\n",
            "Step 501. For the last 100 steps: average loss 0.3300295567924118, accuracy 93\n",
            "Step 601. For the last 100 steps: average loss 0.3933103482662829, accuracy 88\n",
            "Step 701. For the last 100 steps: average loss 0.4406913415274246, accuracy 89\n",
            "Step 801. For the last 100 steps: average loss 0.4557371095398262, accuracy 86\n",
            "Step 901. For the last 100 steps: average loss 0.5308671447935057, accuracy 84\n"
          ]
        }
      ]
    }
  ]
}